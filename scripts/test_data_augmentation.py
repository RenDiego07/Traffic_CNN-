"""
Script para probar y visualizar Data Augmentation con Albumentations

Verifica que las transformaciones de imÃ¡genes y bounding boxes sean correctas,
mostrando comparaciones lado a lado de la imagen original vs augmentada.

Uso:
    python scripts/test_data_augmentation.py
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
import random

# Setup de paths
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)  # IA/
sys.path.insert(0, os.path.join(root_dir, 'src'))


def load_image_and_labels(img_path, label_path, motorized_ids=[0, 1, 4, 5]):
    """
    Carga imagen y sus bounding boxes en formato YOLO.
    
    Args:
        img_path: Ruta a la imagen
        label_path: Ruta al archivo de labels
        motorized_ids: IDs de clases a considerar
        
    Returns:
        tuple: (imagen_array, lista_de_bboxes, class_labels)
    """
    # Cargar imagen
    img = Image.open(img_path).convert('RGB')
    img_array = np.array(img)
    h, w = img_array.shape[:2]
    
    # Cargar bounding boxes
    bboxes = []
    class_labels = []
    
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            lines = f.readlines()
        
        for line in lines:
            parts = line.strip().split()
            if not parts:
                continue
            
            class_id = int(parts[0])
            
            # Filtrar solo vehÃ­culos motorizados
            if class_id in motorized_ids:
                # Coordenadas normalizadas YOLO: center_x, center_y, width, height
                cx, cy, bw, bh = map(float, parts[1:5])
                
                # Convertir de YOLO (center) a Pascal VOC (x_min, y_min, x_max, y_max)
                # y convertir a pÃ­xeles absolutos
                x_min = (cx - bw / 2) * w
                y_min = (cy - bh / 2) * h
                x_max = (cx + bw / 2) * w
                y_max = (cy + bh / 2) * h
                
                # Albumentations espera formato: [x_min, y_min, x_max, y_max] en pÃ­xeles
                bboxes.append([x_min, y_min, x_max, y_max])
                class_labels.append(class_id)
    
    return img_array, bboxes, class_labels


def create_augmentation_pipeline(image_size=512):
    """
    Crea pipeline de data augmentation optimizado para detecciÃ³n de objetos.
    Prioriza mantener los bounding boxes vÃ¡lidos.
    
    Args:
        image_size: TamaÃ±o de salida de la imagen
        
    Returns:
        albumentations.Compose: Pipeline de transformaciones
    """
    transform = A.Compose([
        # 1. Transformaciones geomÃ©tricas SUAVES (para preservar bboxes)
        A.HorizontalFlip(p=0.5),
        
        # TransformaciÃ³n afÃ­n mÃ¡s conservadora
        A.ShiftScaleRotate(
            shift_limit=0.05,     # Desplazamiento reducido a 5%
            scale_limit=0.1,      # Escala reducida a Â±10%
            rotate_limit=5,       # RotaciÃ³n muy suave Â±5 grados
            border_mode=0,
            p=0.5                 # Probabilidad reducida
        ),
        
        # 2. Transformaciones de color/iluminaciÃ³n (NO afectan bboxes)
        A.OneOf([
            A.RandomBrightnessContrast(
                brightness_limit=0.2,
                contrast_limit=0.2,
                p=1.0
            ),
            A.HueSaturationValue(
                hue_shift_limit=15,
                sat_shift_limit=25,
                val_shift_limit=15,
                p=1.0
            ),
            A.ColorJitter(
                brightness=0.2,
                contrast=0.2,
                saturation=0.2,
                hue=0.1,
                p=1.0
            ),
        ], p=0.8),
        
        # 3. Efectos de desenfoque suaves
        A.OneOf([
            A.GaussianBlur(blur_limit=(3, 5), p=1.0),
            A.MotionBlur(blur_limit=5, p=1.0),
        ], p=0.2),
        
        # 4. Ruido
        A.GaussNoise(var_limit=(5.0, 25.0), p=0.2),
        
        # 5. SimulaciÃ³n de clima (conservadora)
        A.RandomRain(
            blur_value=3,
            brightness_coefficient=0.9,
            p=0.1
        ),
        
        A.RandomFog(
            fog_coef_range=(0.05, 0.15),
            alpha_coef=0.08,
            p=0.05
        ),
        
        # 6. Resize final
        A.Resize(height=image_size, width=image_size),
        
    ], bbox_params=A.BboxParams(
        format='pascal_voc',           
        min_visibility=0.2,            # Reducido a 20% para mantener mÃ¡s bboxes
        min_area=20,                   # Ãrea mÃ­nima de 20 pÃ­xeles
        label_fields=['class_labels']  
    ))
    
    return transform


def visualize_comparison(original_img, original_bboxes, augmented_img, augmented_bboxes, 
                        original_labels, augmented_labels, save_path=None):
    """
    Visualiza imagen original vs augmentada con bounding boxes.
    
    Args:
        original_img: Imagen original (numpy array)
        original_bboxes: Bboxes originales (formato pascal_voc normalizado)
        augmented_img: Imagen augmentada
        augmented_bboxes: Bboxes augmentadas
        original_labels: Etiquetas de clase originales
        augmented_labels: Etiquetas de clase augmentadas
        save_path: Ruta para guardar la comparaciÃ³n
    """
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    
    # Imagen original
    ax1 = axes[0]
    ax1.imshow(original_img)
    ax1.set_title(f'Original ({len(original_bboxes)} vehÃ­culos)', fontsize=14, fontweight='bold')
    ax1.axis('off')
    
    # Dibujar bboxes originales (ya en pÃ­xeles)
    for bbox, label in zip(original_bboxes, original_labels):
        x_min, y_min, x_max, y_max = bbox
        
        width = x_max - x_min
        height = y_max - y_min
        
        rect = patches.Rectangle(
            (x_min, y_min), width, height,
            linewidth=2, edgecolor='lime', facecolor='none'
        )
        ax1.add_patch(rect)
        
        # Etiqueta de clase
        ax1.text(x_min, y_min - 5, f'ID:{label}', 
                color='lime', fontsize=9, fontweight='bold',
                bbox=dict(facecolor='black', alpha=0.6, pad=2))
    
    # Imagen augmentada
    ax2 = axes[1]
    ax2.imshow(augmented_img)
    ax2.set_title(f'Augmentada ({len(augmented_bboxes)} vehÃ­culos)', fontsize=14, fontweight='bold')
    ax2.axis('off')
    
    # Dibujar bboxes augmentadas (ya en pÃ­xeles despuÃ©s de Albumentations)
    for bbox, label in zip(augmented_bboxes, augmented_labels):
        x_min, y_min, x_max, y_max = bbox
        
        width = x_max - x_min
        height = y_max - y_min
        
        rect = patches.Rectangle(
            (x_min, y_min), width, height,
            linewidth=2, edgecolor='red', facecolor='none'
        )
        ax2.add_patch(rect)
        
        # Etiqueta de clase
        ax2.text(x_min, y_min - 5, f'ID:{label}', 
                color='red', fontsize=9, fontweight='bold',
                bbox=dict(facecolor='black', alpha=0.6, pad=2))
    
    # InformaciÃ³n adicional
    info_text = (
        f"VehÃ­culos originales: {len(original_bboxes)}\n"
        f"VehÃ­culos despuÃ©s de aug: {len(augmented_bboxes)}\n"
        f"PÃ©rdida: {len(original_bboxes) - len(augmented_bboxes)}"
    )
    
    fig.text(0.5, 0.02, info_text, ha='center', fontsize=11, 
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout(rect=[0, 0.05, 1, 1])
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
        print(f"âœ“ ComparaciÃ³n guardada: {save_path}")
    
    plt.close(fig)


def main():
    """FunciÃ³n principal"""
    print("="*70)
    print("  TEST DE DATA AUGMENTATION CON ALBUMENTATIONS")
    print("="*70)
    
    # Configurar paths
    data_root = os.path.join(root_dir, 'data', 'Intersection-Flow-5K')
    train_img_dir = os.path.join(data_root, 'images', 'train')
    train_label_dir = os.path.join(data_root, 'labels', 'train')
    output_dir = os.path.join(root_dir, 'src', 'infer', 'results', 'augmentation_tests')
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\nğŸ“‚ Directorios:")
    print(f"   Train Images: {train_img_dir}")
    print(f"   Train Labels: {train_label_dir}")
    print(f"   Output: {output_dir}")
    
    # Verificar directorios
    if not os.path.exists(train_img_dir):
        print(f"\nâŒ Error: No se encuentra {train_img_dir}")
        return
    
    # Obtener lista de imÃ¡genes
    img_files = [f for f in os.listdir(train_img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]
    
    if not img_files:
        print("\nâŒ No se encontraron imÃ¡genes")
        return
    
    print(f"\nâœ… Encontradas {len(img_files)} imÃ¡genes de entrenamiento")
    
    # Crear pipeline de augmentation
    print("\nğŸ”§ Creando pipeline de data augmentation...")
    transform = create_augmentation_pipeline(image_size=512)
    print("âœ… Pipeline creado con las siguientes transformaciones:")
    print("   â€¢ Flip horizontal (50%)")
    print("   â€¢ Shift/Scale/Rotate mÃ¡s conservador (50%)")
    print("   â€¢ Brightness/Contrast/HSV/ColorJitter (80%)")
    print("   â€¢ Blur suave (20%)")
    print("   â€¢ Noise (20%)")
    print("   â€¢ Rain (10%) / Fog (5%)")
    print("   â€¢ Min visibility: 20% (mÃ¡s permisivo)")
    print("   â€¢ Min Ã¡rea: 20px")
    
    # Seleccionar muestras aleatorias
    num_samples = min(10, len(img_files))
    sample_files = random.sample(img_files, num_samples)
    
    print(f"\nğŸ² Testeando {num_samples} imÃ¡genes aleatorias...")
    print("   " + "â”€"*66)
    
    successful = 0
    failed = 0
    total_bboxes_original = 0
    total_bboxes_augmented = 0
    
    for i, img_file in enumerate(sample_files, 1):
        img_path = os.path.join(train_img_dir, img_file)
        label_file = os.path.splitext(img_file)[0] + '.txt'
        label_path = os.path.join(train_label_dir, label_file)
        
        try:
            # Cargar imagen y labels
            img_array, bboxes, class_labels = load_image_and_labels(img_path, label_path)
            
            if len(bboxes) == 0:
                print(f"   âš ï¸  [{i}/{num_samples}] {img_file}: Sin vehÃ­culos, saltando...")
                continue
            
            # Aplicar augmentation
            transformed = transform(image=img_array, bboxes=bboxes, class_labels=class_labels)
            
            aug_img = transformed['image']
            aug_bboxes = transformed['bboxes']
            aug_labels = transformed['class_labels']
            
            # EstadÃ­sticas
            total_bboxes_original += len(bboxes)
            total_bboxes_augmented += len(aug_bboxes)
            
            # Visualizar comparaciÃ³n
            output_path = os.path.join(output_dir, f'test_{i}_{os.path.splitext(img_file)[0]}.png')
            visualize_comparison(
                img_array, bboxes, aug_img, aug_bboxes,
                class_labels, aug_labels, output_path
            )
            
            print(f"   âœ“ [{i}/{num_samples}] {img_file}: {len(bboxes)} â†’ {len(aug_bboxes)} vehÃ­culos")
            successful += 1
            
        except Exception as e:
            print(f"   âŒ [{i}/{num_samples}] {img_file}: Error - {e}")
            failed += 1
    
    # Resumen final
    print("\n" + "="*70)
    print("  ğŸ“Š RESUMEN DE PRUEBAS")
    print("="*70)
    print(f"\nâœ… Exitosas: {successful}/{num_samples}")
    print(f"âŒ Fallidas: {failed}/{num_samples}")
    print(f"\nğŸ“¦ Bounding Boxes:")
    print(f"   Original: {total_bboxes_original}")
    print(f"   DespuÃ©s de aug: {total_bboxes_augmented}")
    
    if total_bboxes_original > 0:
        retention = (total_bboxes_augmented / total_bboxes_original) * 100
        print(f"   RetenciÃ³n: {retention:.1f}%")
        
        if retention > 95:
            print("   âœ… Excelente retenciÃ³n de bounding boxes")
        elif retention > 85:
            print("   âœ… Buena retenciÃ³n de bounding boxes")
        else:
            print("   âš ï¸  Baja retenciÃ³n, considera ajustar parÃ¡metros")
    
    print(f"\nğŸ“‚ Visualizaciones guardadas en:")
    print(f"   {output_dir}")
    
    print("\nğŸ’¡ PrÃ³ximos pasos:")
    print("   1. Revisa las visualizaciones para verificar fidelidad")
    print("   2. Ajusta parÃ¡metros del pipeline si es necesario")
    print("   3. Integra el pipeline en tu dataset (dtset.py)")
    print("="*70)


if __name__ == "__main__":
    main()
