# Grid-Based Object Detection for Traffic Flow

Este proyecto implementa un sistema de detecciÃ³n de objetos basado en grid (similar a YOLO) para detectar vehÃ­culos en intersecciones de trÃ¡fico.

## ğŸ¯ Concepto: Grid Detection

El modelo divide la imagen en un **grid de 16x16 celdas**. Cada celda es responsable de predecir:

1. **Objectness** (1 valor): Probabilidad de que haya un objeto en esa celda
2. **Bounding Box** (4 valores):
   - `x_offset`: Desplazamiento horizontal del centro dentro de la celda [0-1]
   - `y_offset`: Desplazamiento vertical del centro dentro de la celda [0-1]
   - `width`: Ancho del objeto (normalizado respecto a la imagen)
   - `height`: Alto del objeto (normalizado respecto a la imagen)
3. **Clase** (5 valores): Probabilidades para cada clase de vehÃ­culo

### Ejemplo Visual

```
Imagen 512x512 â†’ Grid 16x16 (cada celda cubre 32x32 pÃ­xeles)

â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚     â”‚     â”‚  ğŸš— â”‚     â”‚  â† Celda (2,2) detecta un coche
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚     â”‚     â”‚     â”‚     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚     â”‚  ğŸšŒ â”‚     â”‚     â”‚  â† Celda (1,2) detecta un bus
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
src/
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ dtset.py              # Dataset que carga imÃ¡genes y labels YOLO
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cnn_simple.py         # Modelo CNN + funciones de conversiÃ³n y loss
â”œâ”€â”€ train/
â”‚   â””â”€â”€ train_grid_detector.py # Script de entrenamiento
â”œâ”€â”€ infer/
â”‚   â””â”€â”€ infer_grid_detector.py # Script de inferencia
notebooks/
â””â”€â”€ visualize_grid_targets.py # VisualizaciÃ³n del grid
```

## ğŸ”§ Componentes Principales

### 1. Modelo CNN (`GridDetectionCNN`)

Arquitectura:
- **Encoder**: 5 bloques convolucionales que reducen 512x512 â†’ 16x16
- **Detection Head**: Predice para cada celda del grid

```python
Input:  [B, 3, 512, 512]        # ImÃ¡genes RGB
Output: 
  - objectness: [B, 16, 16, 1]  # Heatmap de presencia de objetos
  - bbox:       [B, 16, 16, 4]  # Coordenadas de bounding boxes
  - classes:    [B, 16, 16, 5]  # ClasificaciÃ³n de vehÃ­culos
```

### 2. ConversiÃ³n YOLO â†’ Grid Targets (`yolo_to_grid_targets`)

Convierte las anotaciones YOLO en targets para entrenamiento:

```python
# YOLO format (normalizado)
x_center, y_center, width, height = 0.25, 0.40, 0.10, 0.20

# ConversiÃ³n a grid
cell_x = int(0.25 * 16) = 4
cell_y = int(0.40 * 16) = 6

# Targets
obj_target[6, 4] = 1.0                                    # Marcar celda
bbox_target[6, 4] = [0.00, 0.40, 0.10, 0.20]              # Offsets + tamaÃ±o
class_target[6, 4] = 2                                    # Clase del vehÃ­culo
```

### 3. FunciÃ³n de PÃ©rdida (`compute_loss`)

Combina mÃºltiples pÃ©rdidas ponderadas:

```python
Total Loss = Î»_coord Ã— Loss_bbox + Loss_obj + Î»_noobj Ã— Loss_noobj + Loss_class

Donde:
- Loss_bbox:  MSE para coordenadas (solo en celdas con objetos)
- Loss_obj:   BCE para presencia de objetos
- Loss_noobj: BCE para celdas vacÃ­as (peso reducido)
- Loss_class: Cross-entropy para clasificaciÃ³n
```

**Pesos:**
- `Î»_coord = 5.0`: Penaliza mÃ¡s los errores en localizaciÃ³n
- `Î»_noobj = 0.5`: Reduce la influencia de celdas vacÃ­as (son mayorÃ­a)

## ğŸš€ Uso

### Visualizar el Grid

Primero, visualiza cÃ³mo se convierten los labels YOLO a grid targets:

```bash
cd notebooks
python visualize_grid_targets.py
```

Esto genera `outputs/grid_visualization.png` mostrando:
- Imagen original con bounding boxes YOLO
- Heatmap de objectness
- Grid con offsets detallados

### Entrenar el Modelo

```bash
cd src/train
python train_grid_detector.py
```

**ParÃ¡metros configurables:**
```python
BATCH_SIZE = 8
EPOCHS = 50
LEARNING_RATE = 1e-3
GRID_SIZE = 16
NUM_CLASSES = 5
```

El entrenamiento guarda:
- `models/checkpoints/best_model.pth`: Mejor modelo basado en validation loss
- `models/checkpoints/model_epoch_X.pth`: Checkpoints cada 10 Ã©pocas

### Inferencia

```bash
cd src/infer
python infer_grid_detector.py
```

Genera detecciones con visualizaciÃ³n en `outputs/detection_result.png`.

## ğŸ“Š Clases de VehÃ­culos

```python
0: "car"         # AutomÃ³vil
1: "truck"       # CamiÃ³n
2: "bus"         # AutobÃºs
3: "motorcycle"  # Motocicleta
4: "bicycle"     # Bicicleta
```

## ğŸ“ Conceptos Clave

### Â¿Por quÃ© Grid Detection?

1. **Eficiencia**: Una sola pasada por la red predice todos los objetos
2. **LocalizaciÃ³n espacial**: Cada celda es responsable de su regiÃ³n
3. **Escalabilidad**: FÃ¡cil de adaptar a diferentes resoluciones de grid

### ComparaciÃ³n con YOLO Original

| Aspecto | Este Proyecto | YOLO v1 |
|---------|--------------|---------|
| Grid | 16Ã—16 | 7Ã—7 o 13Ã—13 |
| Anchors | No usa | No usa (v1) |
| Backbone | CNN simple | Darknet |
| Clases | 5 | 20/80 |

### Limitaciones Actuales

1. **Una detecciÃ³n por celda**: Si hay mÃºltiples objetos en la misma celda, solo detecta uno
2. **Objetos pequeÃ±os**: El grid 16Ã—16 puede no capturar objetos muy pequeÃ±os
3. **Sin Non-Maximum Suppression (NMS)**: Pueden haber detecciones duplicadas en celdas adyacentes

### Posibles Mejoras

- [ ] Implementar mÃºltiples anchor boxes por celda
- [ ] AÃ±adir NMS para eliminar detecciones duplicadas
- [ ] Usar Feature Pyramid Network para detectar objetos a mÃºltiples escalas
- [ ] Data augmentation (rotaciones, cambios de color, etc.)
- [ ] Backbone pre-entrenado (ResNet, EfficientNet)

## ğŸ“ˆ Monitoreo del Entrenamiento

Durante el entrenamiento, observa:

```
Train Loss: 0.8234
  - BBox: 0.1245    # â† Debe bajar (mejor localizaciÃ³n)
  - Obj: 0.3421     # â† Debe bajar (mejor detecciÃ³n)
  - NoObj: 0.2156   # â† Debe bajar (menos falsos positivos)
  - Class: 0.1412   # â† Debe bajar (mejor clasificaciÃ³n)
```

**SeÃ±ales de buen entrenamiento:**
- Training loss baja consistentemente
- Validation loss sigue al training loss (sin overfitting)
- BBox loss < 0.1 indica buena localizaciÃ³n

## ğŸ› ï¸ Troubleshooting

**Problema**: Loss muy alto al inicio
- **SoluciÃ³n**: Normal, espera 5-10 Ã©pocas para que converja

**Problema**: Validation loss sube mientras training loss baja
- **SoluciÃ³n**: Overfitting â†’ reduce learning rate o aÃ±ade dropout

**Problema**: No detecta objetos pequeÃ±os
- **SoluciÃ³n**: Aumenta grid_size a 32Ã—32 o 64Ã—64

**Problema**: MÃºltiples detecciones del mismo objeto
- **SoluciÃ³n**: Implementa NMS en el script de inferencia

## ğŸ“š Referencias

- [YOLO v1 Paper](https://arxiv.org/abs/1506.02640)
- [Understanding YOLO](https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088)
- [Grid-based Detection Explained](https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006)

## ğŸ™ CrÃ©ditos

Dataset: [Intersection-Flow-5K](https://github.com/yourusername/intersection-flow-5k)
